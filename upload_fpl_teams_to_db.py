#!/usr/bin/env python3
"""
Script to upload FPL teams CSV data to Supabase fpl_teams table.
This script reads the CSV file generated by scrape_fpl_teams.py and uploads
the data to the Supabase database.
"""
import sys
import csv
import logging
from pathlib import Path
from typing import List, Dict

sys.path.insert(0, str(Path(__file__).parent / "src"))

from database import DatabaseManager

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def read_csv_file(csv_path: str) -> List[Dict]:
    """
    Read the CSV file and return list of records.
    """
    records = []
    with open(csv_path, 'r', encoding='utf-8') as csvfile:
        reader = csv.DictReader(csvfile)
        for row in reader:
            # Map CSV columns to database columns
            # CSV has: id, team_name, manager_name, region, overall_points, overall_rank
            # Database needs: team_id, team_name, manager_name
            if row.get('id') and row.get('team_name') and row.get('manager_name'):
                records.append({
                    'team_id': int(row['id']),
                    'team_name': row['team_name'].strip(),
                    'manager_name': row['manager_name'].strip()
                })
    return records


def upload_to_database(db_manager: DatabaseManager, records: List[Dict], batch_size: int = 1000):
    """
    Upload records to Supabase fpl_teams table using upsert.
    """
    if not db_manager or not db_manager.supabase_client:
        logger.error("Database manager or Supabase client not available")
        return False
    
    total_records = len(records)
    logger.info(f"Uploading {total_records} records to fpl_teams table (batch size: {batch_size})")
    
    # Process in batches to avoid overwhelming the API
    uploaded = 0
    failed = 0
    
    for i in range(0, total_records, batch_size):
        batch = records[i:i + batch_size]
        batch_num = (i // batch_size) + 1
        total_batches = (total_records + batch_size - 1) // batch_size
        
        try:
            # Use upsert to handle duplicates (on team_id)
            response = db_manager.supabase_client.table('fpl_teams').upsert(
                batch,
                on_conflict='team_id'
            ).execute()
            
            uploaded += len(batch)
            logger.info(f"Batch {batch_num}/{total_batches}: Uploaded {len(batch)} records (Total: {uploaded}/{total_records})")
            
        except Exception as e:
            logger.error(f"Error uploading batch {batch_num}/{total_batches}: {e}")
            failed += len(batch)
            # Continue with next batch
    
    logger.info(f"Upload complete: {uploaded} successful, {failed} failed")
    return failed == 0


def main():
    import argparse
    
    parser = argparse.ArgumentParser(description="Upload FPL teams CSV to Supabase database")
    parser.add_argument(
        "--csv",
        type=str,
        default="fpl_teams.csv",
        help="Path to CSV file (default: fpl_teams.csv)"
    )
    parser.add_argument(
        "--batch-size",
        type=int,
        default=1000,
        help="Number of records per batch (default: 1000)"
    )
    
    args = parser.parse_args()
    
    # Check if CSV file exists
    csv_path = Path(args.csv)
    if not csv_path.exists():
        logger.error(f"CSV file not found: {csv_path}")
        sys.exit(1)
    
    # Initialize database manager
    logger.info("Initializing database manager...")
    try:
        db_manager = DatabaseManager()
        if not db_manager.supabase_client:
            logger.error("Supabase client not available. Check SUPABASE_URL and SUPABASE_KEY environment variables.")
            sys.exit(1)
        logger.info("Database manager initialized successfully")
    except Exception as e:
        logger.error(f"Failed to initialize database manager: {e}")
        sys.exit(1)
    
    # Read CSV file
    logger.info(f"Reading CSV file: {csv_path}")
    try:
        records = read_csv_file(str(csv_path))
        logger.info(f"Read {len(records)} records from CSV")
        if not records:
            logger.warning("No valid records found in CSV file")
            sys.exit(1)
    except Exception as e:
        logger.error(f"Error reading CSV file: {e}")
        sys.exit(1)
    
    # Upload to database
    logger.info("Starting database upload...")
    success = upload_to_database(db_manager, records, batch_size=args.batch_size)
    
    if success:
        logger.info("✅ Upload completed successfully!")
        sys.exit(0)
    else:
        logger.error("❌ Upload completed with errors")
        sys.exit(1)


if __name__ == "__main__":
    main()

